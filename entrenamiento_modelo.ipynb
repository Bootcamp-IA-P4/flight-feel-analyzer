{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec078ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIO DEL PREPROCESAMIENTO ---\n",
      "\n",
      "--- 1. Carga y Exploración Inicial ---\n",
      "Primeras 5 filas del dataset:\n",
      "       id  Gender      Customer Type  Age   Type of Travel     Class  \\\n",
      "0   70172    Male     Loyal Customer   13  Personal Travel  Eco Plus   \n",
      "1    5047    Male  disloyal Customer   25  Business travel  Business   \n",
      "2  110028  Female     Loyal Customer   26  Business travel  Business   \n",
      "3   24026  Female     Loyal Customer   25  Business travel  Business   \n",
      "4  119299    Male     Loyal Customer   61  Business travel  Business   \n",
      "\n",
      "   Flight Distance  Inflight wifi service  Departure/Arrival time convenient  \\\n",
      "0              460                      3                                  4   \n",
      "1              235                      3                                  2   \n",
      "2             1142                      2                                  2   \n",
      "3              562                      2                                  5   \n",
      "4              214                      3                                  3   \n",
      "\n",
      "   Ease of Online booking  ...  Inflight entertainment  On-board service  \\\n",
      "0                       3  ...                       5                 4   \n",
      "1                       3  ...                       1                 1   \n",
      "2                       2  ...                       5                 4   \n",
      "3                       5  ...                       2                 2   \n",
      "4                       3  ...                       3                 3   \n",
      "\n",
      "   Leg room service  Baggage handling  Checkin service  Inflight service  \\\n",
      "0                 3                 4                4                 5   \n",
      "1                 5                 3                1                 4   \n",
      "2                 3                 4                4                 4   \n",
      "3                 5                 3                1                 4   \n",
      "4                 4                 4                3                 3   \n",
      "\n",
      "   Cleanliness  Departure Delay in Minutes  Arrival Delay in Minutes  \\\n",
      "0            5                          25                      18.0   \n",
      "1            1                           1                       6.0   \n",
      "2            5                           0                       0.0   \n",
      "3            2                          11                       9.0   \n",
      "4            3                           0                       0.0   \n",
      "\n",
      "              satisfaction  \n",
      "0  neutral or dissatisfied  \n",
      "1  neutral or dissatisfied  \n",
      "2                satisfied  \n",
      "3  neutral or dissatisfied  \n",
      "4                satisfied  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 0 to 999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   id                                 1000 non-null   int64  \n",
      " 1   Gender                             1000 non-null   object \n",
      " 2   Customer Type                      1000 non-null   object \n",
      " 3   Age                                1000 non-null   int64  \n",
      " 4   Type of Travel                     1000 non-null   object \n",
      " 5   Class                              1000 non-null   object \n",
      " 6   Flight Distance                    1000 non-null   int64  \n",
      " 7   Inflight wifi service              1000 non-null   int64  \n",
      " 8   Departure/Arrival time convenient  1000 non-null   int64  \n",
      " 9   Ease of Online booking             1000 non-null   int64  \n",
      " 10  Gate location                      1000 non-null   int64  \n",
      " 11  Food and drink                     1000 non-null   int64  \n",
      " 12  Online boarding                    1000 non-null   int64  \n",
      " 13  Seat comfort                       1000 non-null   int64  \n",
      " 14  Inflight entertainment             1000 non-null   int64  \n",
      " 15  On-board service                   1000 non-null   int64  \n",
      " 16  Leg room service                   1000 non-null   int64  \n",
      " 17  Baggage handling                   1000 non-null   int64  \n",
      " 18  Checkin service                    1000 non-null   int64  \n",
      " 19  Inflight service                   1000 non-null   int64  \n",
      " 20  Cleanliness                        1000 non-null   int64  \n",
      " 21  Departure Delay in Minutes         1000 non-null   int64  \n",
      " 22  Arrival Delay in Minutes           999 non-null    float64\n",
      " 23  satisfaction                       1000 non-null   object \n",
      "dtypes: float64(1), int64(18), object(5)\n",
      "memory usage: 195.3+ KB\n",
      "\n",
      "--- 2. Limpieza de Datos ---\n",
      "\n",
      "Valores faltantes por columna ANTES del tratamiento:\n",
      "id                                   0\n",
      "Gender                               0\n",
      "Customer Type                        0\n",
      "Age                                  0\n",
      "Type of Travel                       0\n",
      "Class                                0\n",
      "Flight Distance                      0\n",
      "Inflight wifi service                0\n",
      "Departure/Arrival time convenient    0\n",
      "Ease of Online booking               0\n",
      "Gate location                        0\n",
      "Food and drink                       0\n",
      "Online boarding                      0\n",
      "Seat comfort                         0\n",
      "Inflight entertainment               0\n",
      "On-board service                     0\n",
      "Leg room service                     0\n",
      "Baggage handling                     0\n",
      "Checkin service                      0\n",
      "Inflight service                     0\n",
      "Cleanliness                          0\n",
      "Departure Delay in Minutes           0\n",
      "Arrival Delay in Minutes             1\n",
      "satisfaction                         0\n",
      "dtype: int64\n",
      "\n",
      "'Arrival Delay in Minutes' imputado con mediana (0.0) y convertido a int.\n",
      "\n",
      "Valores faltantes por columna DESPUÉS de la imputación:\n",
      "id                                   0\n",
      "Gender                               0\n",
      "Customer Type                        0\n",
      "Age                                  0\n",
      "Type of Travel                       0\n",
      "Class                                0\n",
      "Flight Distance                      0\n",
      "Inflight wifi service                0\n",
      "Departure/Arrival time convenient    0\n",
      "Ease of Online booking               0\n",
      "Gate location                        0\n",
      "Food and drink                       0\n",
      "Online boarding                      0\n",
      "Seat comfort                         0\n",
      "Inflight entertainment               0\n",
      "On-board service                     0\n",
      "Leg room service                     0\n",
      "Baggage handling                     0\n",
      "Checkin service                      0\n",
      "Inflight service                     0\n",
      "Cleanliness                          0\n",
      "Departure Delay in Minutes           0\n",
      "Arrival Delay in Minutes             0\n",
      "satisfaction                         0\n",
      "dtype: int64\n",
      "\n",
      "Columnas ['id'] eliminadas.\n",
      "\n",
      "--- 3. Transformación de Datos ---\n",
      "\n",
      "Target 'satisfaction' mapeado a numérico.\n",
      "Columna 'Gender' mapeada a numérico.\n",
      "Columna 'Customer Type' mapeada a numérico.\n",
      "Columna 'Type of Travel' mapeada a numérico.\n",
      "Columna 'Class' mapeada a numérico (ordinal).\n",
      "\n",
      "Verificación de tipos después de mapeos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 0 to 999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                             Non-Null Count  Dtype\n",
      "---  ------                             --------------  -----\n",
      " 0   Gender                             1000 non-null   int64\n",
      " 1   Customer Type                      1000 non-null   int64\n",
      " 2   Age                                1000 non-null   int64\n",
      " 3   Type of Travel                     1000 non-null   int64\n",
      " 4   Class                              1000 non-null   int64\n",
      " 5   Flight Distance                    1000 non-null   int64\n",
      " 6   Inflight wifi service              1000 non-null   int64\n",
      " 7   Departure/Arrival time convenient  1000 non-null   int64\n",
      " 8   Ease of Online booking             1000 non-null   int64\n",
      " 9   Gate location                      1000 non-null   int64\n",
      " 10  Food and drink                     1000 non-null   int64\n",
      " 11  Online boarding                    1000 non-null   int64\n",
      " 12  Seat comfort                       1000 non-null   int64\n",
      " 13  Inflight entertainment             1000 non-null   int64\n",
      " 14  On-board service                   1000 non-null   int64\n",
      " 15  Leg room service                   1000 non-null   int64\n",
      " 16  Baggage handling                   1000 non-null   int64\n",
      " 17  Checkin service                    1000 non-null   int64\n",
      " 18  Inflight service                   1000 non-null   int64\n",
      " 19  Cleanliness                        1000 non-null   int64\n",
      " 20  Departure Delay in Minutes         1000 non-null   int64\n",
      " 21  Arrival Delay in Minutes           1000 non-null   int64\n",
      " 22  satisfaction                       1000 non-null   int64\n",
      "dtypes: int64(23)\n",
      "memory usage: 187.5 KB\n",
      "\n",
      "Nueva característica 'Total Delay in Minutes' creada.\n",
      "\n",
      "Columnas escaladas: ['Gender', 'Customer Type', 'Age', 'Type of Travel', 'Class', 'Flight Distance', 'Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking', 'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes', 'Total Delay in Minutes']\n",
      "Scaler guardado en: app/ml_models\\standard_scaler.pkl\n",
      "Lista de columnas a escalar guardada en: app/ml_models\\cols_to_scale.joblib\n",
      "\n",
      "Dataset preprocesado guardado localmente como './data\\data_short_preprocessed.csv'\n",
      "\n",
      "--- FIN DEL PREPROCESAMIENTO ---\n",
      "El DataFrame 'df_transformed' está listo para los siguientes pasos.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import joblib # IMPORTANTE\n",
    "\n",
    "print(\"--- INICIO DEL PREPROCESAMIENTO ---\")\n",
    "\n",
    "# --- 1. Comprensión Inicial de los Datos ---\n",
    "print(\"\\n--- 1. Carga y Exploración Inicial ---\")\n",
    "data_dir_for_short = './data'\n",
    "data_short_path = os.path.join(data_dir_for_short, 'data_short.csv')\n",
    "full_data_path_original = './data/airline_passenger_satisfaction.csv' # Asumiendo que data también está en la raíz\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(data_dir_for_short):\n",
    "        os.makedirs(data_dir_for_short)\n",
    "        print(f\"Directorio '{data_dir_for_short}' creado.\")\n",
    "\n",
    "    if not os.path.exists(data_short_path):\n",
    "        print(f\"'{data_short_path}' no encontrado.\")\n",
    "        if os.path.exists(full_data_path_original):\n",
    "            print(f\"Creando '{data_short_path}' como una muestra de '{full_data_path_original}'.\")\n",
    "            df_full = pd.read_csv(full_data_path_original)\n",
    "            if 'Unnamed: 0' in df_full.columns:\n",
    "                 df_full = df_full.drop(columns=['Unnamed: 0'])\n",
    "            df_full.sample(n=1000, random_state=42).to_csv(data_short_path, index=False)\n",
    "            print(f\"'{data_short_path}' creado con 1000 filas y sin índice de pandas en el archivo.\")\n",
    "            df = pd.read_csv(data_short_path)\n",
    "        else:\n",
    "            print(f\"Error: Ni '{data_short_path}' ni '{full_data_path_original}' (para muestra) encontrados.\")\n",
    "            exit()\n",
    "    else:\n",
    "        df = pd.read_csv(data_short_path)\n",
    "        if df.columns[0] == 'Unnamed: 0' and df.index.name is None : # Si la primera es un índice sin nombre\n",
    "             df = pd.read_csv(data_short_path, index_col=0)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error al cargar los datos: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Primeras 5 filas del dataset:\")\n",
    "print(df.head())\n",
    "df.info()\n",
    "\n",
    "# --- 2. Limpieza de Datos ---\n",
    "print(\"\\n--- 2. Limpieza de Datos ---\")\n",
    "print(\"\\nValores faltantes por columna ANTES del tratamiento:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "if 'Arrival Delay in Minutes' in df.columns and df['Arrival Delay in Minutes'].isnull().any():\n",
    "    median_arrival_delay = df['Arrival Delay in Minutes'].median()\n",
    "    df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].fillna(median_arrival_delay)\n",
    "    df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].astype(int)\n",
    "    print(f\"\\n'Arrival Delay in Minutes' imputado con mediana ({median_arrival_delay}) y convertido a int.\")\n",
    "else:\n",
    "    print(\"\\nNo hay valores faltantes en 'Arrival Delay in Minutes' o la columna no existe.\")\n",
    "\n",
    "print(\"\\nValores faltantes por columna DESPUÉS de la imputación:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "columns_to_drop = []\n",
    "if 'id' in df.columns:\n",
    "    columns_to_drop.append('id')\n",
    "if 'ID' in df.columns:\n",
    "    columns_to_drop.append('ID')\n",
    "\n",
    "if columns_to_drop:\n",
    "    df_cleaned = df.drop(columns=columns_to_drop, axis=1)\n",
    "    print(f\"\\nColumnas {columns_to_drop} eliminadas.\")\n",
    "else:\n",
    "    df_cleaned = df.copy()\n",
    "    print(\"\\nNo se encontraron columnas 'id' o 'ID' para eliminar.\")\n",
    "\n",
    "# --- 3. Transformación de Datos (Feature Engineering & Encoding) ---\n",
    "print(\"\\n--- 3. Transformación de Datos ---\")\n",
    "df_transformed = df_cleaned.copy()\n",
    "\n",
    "if 'satisfaction' in df_transformed.columns and df_transformed['satisfaction'].dtype == 'object':\n",
    "    satisfaction_map = {'neutral or dissatisfied': 0, 'satisfied': 1}\n",
    "    df_transformed['satisfaction'] = df_transformed['satisfaction'].map(satisfaction_map)\n",
    "    print(\"\\nTarget 'satisfaction' mapeado a numérico.\")\n",
    "\n",
    "if 'Gender' in df_transformed.columns and df_transformed['Gender'].dtype == 'object':\n",
    "    gender_map = {'Male': 0, 'Female': 1}\n",
    "    df_transformed['Gender'] = df_transformed['Gender'].map(gender_map)\n",
    "    print(\"Columna 'Gender' mapeada a numérico.\")\n",
    "\n",
    "if 'Customer Type' in df_transformed.columns and df_transformed['Customer Type'].dtype == 'object':\n",
    "    customer_type_map = {'Loyal Customer': 1, 'disloyal Customer': 0}\n",
    "    df_transformed['Customer Type'] = df_transformed['Customer Type'].map(customer_type_map)\n",
    "    print(\"Columna 'Customer Type' mapeada a numérico.\")\n",
    "\n",
    "if 'Type of Travel' in df_transformed.columns and df_transformed['Type of Travel'].dtype == 'object':\n",
    "    travel_type_map = {'Personal Travel': 0, 'Business travel': 1}\n",
    "    df_transformed['Type of Travel'] = df_transformed['Type of Travel'].map(travel_type_map)\n",
    "    print(\"Columna 'Type of Travel' mapeada a numérico.\")\n",
    "\n",
    "if 'Class' in df_transformed.columns and df_transformed['Class'].dtype == 'object':\n",
    "    class_map = {'Eco': 0, 'Eco Plus': 1, 'Business': 2}\n",
    "    df_transformed['Class'] = df_transformed['Class'].map(class_map)\n",
    "    print(\"Columna 'Class' mapeada a numérico (ordinal).\")\n",
    "\n",
    "print(\"\\nVerificación de tipos después de mapeos:\")\n",
    "df_transformed.info()\n",
    "\n",
    "if df_transformed.isnull().sum().any():\n",
    "    print(\"\\n¡Advertencia! Se encontraron NaNs después de los mapeos. Verificando...\")\n",
    "    print(df_transformed.isnull().sum()[df_transformed.isnull().sum() > 0])\n",
    "    for col in ['Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']:\n",
    "        if col in df_transformed.columns and df_transformed[col].isnull().any():\n",
    "            print(f\"Llenando NaNs en '{col}' con 0 (asumiendo fallo de mapeo o valor no esperado).\")\n",
    "            df_transformed[col] = df_transformed[col].fillna(0)\n",
    "\n",
    "if 'Departure Delay in Minutes' in df_transformed.columns and 'Arrival Delay in Minutes' in df_transformed.columns:\n",
    "    df_transformed['Total Delay in Minutes'] = df_transformed['Departure Delay in Minutes'] + df_transformed['Arrival Delay in Minutes']\n",
    "    print(\"\\nNueva característica 'Total Delay in Minutes' creada.\")\n",
    "\n",
    "numeric_cols_for_scaling = df_transformed.select_dtypes(include=np.number).columns.tolist()\n",
    "cols_to_exclude_from_scaling = ['satisfaction']\n",
    "cols_to_scale = [col for col in numeric_cols_for_scaling if col not in cols_to_exclude_from_scaling and col in df_transformed.columns]\n",
    "\n",
    "# Directorio para guardar modelos de la app Flask\n",
    "# ASUMIENDO QUE EL NOTEBOOK ESTÁ EN LA RAÍZ DEL PROYECTO, JUNTO A LA CARPETA 'app'\n",
    "ML_MODELS_APP_DIR = 'app/ml_models' # <--- ¡¡¡CAMBIO IMPORTANTE SI EL NOTEBOOK ESTÁ EN LA RAÍZ!!!\n",
    "                                    # Si el notebook está en 'notebooks/', usarías '../app/ml_models'\n",
    "\n",
    "if not os.path.exists(ML_MODELS_APP_DIR):\n",
    "    os.makedirs(ML_MODELS_APP_DIR)\n",
    "    print(f\"Directorio '{ML_MODELS_APP_DIR}' creado para los artefactos del modelo.\")\n",
    "\n",
    "scaler_object = None\n",
    "if cols_to_scale:\n",
    "    scaler_object = StandardScaler()\n",
    "    df_transformed[cols_to_scale] = scaler_object.fit_transform(df_transformed[cols_to_scale])\n",
    "    print(f\"\\nColumnas escaladas: {cols_to_scale}\")\n",
    "\n",
    "    scaler_path = os.path.join(ML_MODELS_APP_DIR, 'standard_scaler.pkl')\n",
    "    cols_to_scale_path = os.path.join(ML_MODELS_APP_DIR, 'cols_to_scale.joblib')\n",
    "\n",
    "    joblib.dump(scaler_object, scaler_path)\n",
    "    print(f\"Scaler guardado en: {scaler_path}\")\n",
    "    joblib.dump(cols_to_scale, cols_to_scale_path)\n",
    "    print(f\"Lista de columnas a escalar guardada en: {cols_to_scale_path}\")\n",
    "else:\n",
    "    print(\"\\nNo se encontraron columnas para escalar.\")\n",
    "    cols_to_scale_path = os.path.join(ML_MODELS_APP_DIR, 'cols_to_scale.joblib')\n",
    "    joblib.dump([], cols_to_scale_path)\n",
    "    print(f\"Lista de columnas a escalar (vacía) guardada en: {cols_to_scale_path}\")\n",
    "    scaler_path = os.path.join(ML_MODELS_APP_DIR, 'standard_scaler.pkl')\n",
    "    joblib.dump(None, scaler_path)\n",
    "    print(f\"Scaler (None) guardado en: {scaler_path}\")\n",
    "\n",
    "local_preprocessed_path = os.path.join(data_dir_for_short, 'data_short_preprocessed.csv')\n",
    "try:\n",
    "    df_transformed.to_csv(local_preprocessed_path, index=True)\n",
    "    print(f\"\\nDataset preprocesado guardado localmente como '{local_preprocessed_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError al guardar el archivo preprocesado localmente: {e}\")\n",
    "\n",
    "print(\"\\n--- FIN DEL PREPROCESAMIENTO ---\")\n",
    "print(\"El DataFrame 'df_transformed' está listo para los siguientes pasos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f831bf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Cargando datos preprocesados ---\n",
      "Datos cargados correctamente desde './data\\data_short_preprocessed.csv'.\n",
      "\n",
      "--- 2. Preparando datos para modelado ---\n",
      "Forma de X (características): (1000, 23)\n",
      "Forma de y (target): (1000,)\n",
      "Orden de características (23 features) guardado en: app/ml_models\\feature_order.joblib\n",
      "\n",
      "--- 3. Dividiendo datos en conjuntos de Entrenamiento y Prueba ---\n",
      "Tamaño Entrenamiento: X=(800, 23), y=(800,)\n",
      "Tamaño Prueba:        X=(200, 23), y=(200,)\n",
      "\n",
      "Distribución de 'satisfaction' en Entrenamiento:\n",
      "satisfaction\n",
      "0    0.56\n",
      "1    0.44\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribución de 'satisfaction' en Prueba:\n",
      "satisfaction\n",
      "0    0.56\n",
      "1    0.44\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- 1. Cargar Datos Preprocesados ---\n",
    "print(\"--- 1. Cargando datos preprocesados ---\")\n",
    "data_dir_for_short = './data'\n",
    "preprocessed_file_path = os.path.join(data_dir_for_short, 'data_short_preprocessed.csv')\n",
    "\n",
    "try:\n",
    "    df_processed = pd.read_csv(preprocessed_file_path, index_col=0)\n",
    "    print(f\"Datos cargados correctamente desde '{preprocessed_file_path}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{preprocessed_file_path}' no encontrado.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el archivo: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Preparar Datos para Modelado (X e y) ---\n",
    "print(\"\\n--- 2. Preparando datos para modelado ---\")\n",
    "try:\n",
    "    if 'satisfaction' not in df_processed.columns:\n",
    "        raise KeyError(\"La columna 'satisfaction' no se encuentra. Revisa el CSV preprocesado.\")\n",
    "    X = df_processed.drop('satisfaction', axis=1)\n",
    "    y = df_processed['satisfaction']\n",
    "    print(f\"Forma de X (características): {X.shape}\")\n",
    "    print(f\"Forma de y (target): {y.shape}\")\n",
    "\n",
    "    # --- GUARDAR ORDEN DE CARACTERÍSTICAS ---\n",
    "    # ASUMIENDO QUE EL NOTEBOOK ESTÁ EN LA RAÍZ DEL PROYECTO, JUNTO A LA CARPETA 'app'\n",
    "    ML_MODELS_APP_DIR = 'app/ml_models' # <--- ¡¡¡CAMBIO IMPORTANTE SI EL NOTEBOOK ESTÁ EN LA RAÍZ!!!\n",
    "                                        # Si el notebook está en 'notebooks/', usarías '../app/ml_models'\n",
    "\n",
    "    if not os.path.exists(ML_MODELS_APP_DIR):\n",
    "        os.makedirs(ML_MODELS_APP_DIR)\n",
    "        print(f\"Directorio '{ML_MODELS_APP_DIR}' creado para los artefactos del modelo.\")\n",
    "\n",
    "    feature_order_path = os.path.join(ML_MODELS_APP_DIR, 'feature_order.joblib')\n",
    "    feature_order_list = list(X.columns)\n",
    "    joblib.dump(feature_order_list, feature_order_path)\n",
    "    print(f\"Orden de características ({len(feature_order_list)} features) guardado en: {feature_order_path}\")\n",
    "\n",
    "except KeyError as ke:\n",
    "    print(f\"Error: {ke}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al separar X e y: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Dividir Datos en Entrenamiento y Prueba ---\n",
    "print(\"\\n--- 3. Dividiendo datos en conjuntos de Entrenamiento y Prueba ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "print(f\"Tamaño Entrenamiento: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Tamaño Prueba:        X={X_test.shape}, y={y_test.shape}\")\n",
    "print(\"\\nDistribución de 'satisfaction' en Entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nDistribución de 'satisfaction' en Prueba:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fbebab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- COMPARACIÓN INICIAL DE MODELOS (OPCIONAL) ---\n",
      "\n",
      "--- Evaluando 8 modelos usando 5-Fold Cross-Validation (sobre datos COMPLETOS X, y) ---\n",
      "Evaluando: Logistic Regression...\n",
      "  Completado en 0.18 segundos. AUC: 0.9278\n",
      "Evaluando: KNN (k=5)...\n",
      "  Completado en 0.34 segundos. AUC: 0.9368\n",
      "Evaluando: SVC (RBF)...\n",
      "  Completado en 0.88 segundos. AUC: 0.9579\n",
      "Evaluando: Decision Tree...\n",
      "  Completado en 0.76 segundos. AUC: 0.8903\n",
      "Evaluando: Random Forest (Default)...\n",
      "  Completado en 0.88 segundos. AUC: 0.9685\n",
      "Evaluando: Gradient Boosting (Default)...\n",
      "  Completado en 0.92 segundos. AUC: 0.9747\n",
      "Evaluando: AdaBoost...\n",
      "  Completado en 0.83 segundos. AUC: 0.9611\n",
      "Evaluando: Gaussian Naive Bayes...\n",
      "  Completado en 0.70 segundos. AUC: 0.9257\n",
      "\n",
      "Ranking de Modelos (Validación Cruzada General):\n",
      "                             AUC (mean)  F1 Weighted (mean)  Accuracy (mean)  \\\n",
      "Gradient Boosting (Default)      0.9747              0.9257            0.926   \n",
      "Random Forest (Default)          0.9685              0.9216            0.922   \n",
      "AdaBoost                         0.9611              0.8979            0.898   \n",
      "SVC (RBF)                        0.9579              0.9067            0.907   \n",
      "KNN (k=5)                        0.9368              0.8927            0.893   \n",
      "Logistic Regression              0.9278              0.8698            0.870   \n",
      "Gaussian Naive Bayes             0.9257              0.8508            0.851   \n",
      "Decision Tree                    0.8903              0.8928            0.893   \n",
      "\n",
      "                             Fit Time (mean)  \n",
      "Gradient Boosting (Default)           0.1477  \n",
      "Random Forest (Default)               0.1044  \n",
      "AdaBoost                              0.0578  \n",
      "SVC (RBF)                             0.0553  \n",
      "KNN (k=5)                             0.0033  \n",
      "Logistic Regression                   0.0040  \n",
      "Gaussian Naive Bayes                  0.0018  \n",
      "Decision Tree                         0.0046  \n"
     ]
    }
   ],
   "source": [
    "# CELDA 3: COMPARACIÓN INICIAL DE MODELOS (OPCIONAL)\n",
    "\n",
    "# Modelos de Clasificación\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from xgboost import XGBClassifier # Descomentar si tienes XGBoost\n",
    "# from lightgbm import LGBMClassifier # Descomentar si tienes LightGBM\n",
    "\n",
    "# Utilidades de Scikit-learn\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score # roc_auc_score ya debería estar\n",
    "from time import time # Asegurarse que time esté importado aquí también\n",
    "\n",
    "print(\"\\n--- COMPARACIÓN INICIAL DE MODELOS (OPCIONAL) ---\")\n",
    "# Lista de modelos a evaluar\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, solver='liblinear'),\n",
    "    \"KNN (k=5)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SVC (RBF)\": SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest (Default)\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting (Default)\": GradientBoostingClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "\n",
    "n_folds = 5\n",
    "# X e y deben estar definidos desde la Celda 2\n",
    "cv_strategy = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "scoring_metrics = ['accuracy', 'f1_weighted', 'roc_auc']\n",
    "results_cv = {}\n",
    "\n",
    "print(f\"\\n--- Evaluando {len(models)} modelos usando {n_folds}-Fold Cross-Validation (sobre datos COMPLETOS X, y) ---\")\n",
    "for model_name, model in models.items():\n",
    "    start_time_cv = time() # Renombrar variable para evitar colisión si 'start_time' se usa después\n",
    "    print(f\"Evaluando: {model_name}...\")\n",
    "    try:\n",
    "        # Usar X e y globales (todo el dataset preprocesado antes del split train/test para esta comparación general)\n",
    "        cv_results_data = cross_validate(model, X, y, cv=cv_strategy, scoring=scoring_metrics, n_jobs=-1)\n",
    "        results_cv[model_name] = {\n",
    "            'Fit Time (mean)': cv_results_data['fit_time'].mean(),\n",
    "            'Accuracy (mean)': cv_results_data['test_accuracy'].mean(),\n",
    "            'F1 Weighted (mean)': cv_results_data['test_f1_weighted'].mean(),\n",
    "            'AUC (mean)': cv_results_data['test_roc_auc'].mean(),\n",
    "        }\n",
    "        elapsed_time_cv = time() - start_time_cv\n",
    "        print(f\"  Completado en {elapsed_time_cv:.2f} segundos. AUC: {results_cv[model_name]['AUC (mean)']:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error evaluando {model_name}: {e}\")\n",
    "        results_cv[model_name] = {metric: np.nan for metric in scoring_metrics + ['fit_time']}\n",
    "\n",
    "results_cv_df = pd.DataFrame(results_cv).T.sort_values(by='AUC (mean)', ascending=False)\n",
    "print(\"\\nRanking de Modelos (Validación Cruzada General):\")\n",
    "print(results_cv_df[['AUC (mean)', 'F1 Weighted (mean)', 'Accuracy (mean)', 'Fit Time (mean)']].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfc66c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. AJUSTE DE HIPERPARÁMETROS PARA RANDOM FOREST (Enfoque Compañeros) ---\n",
      "\n",
      "Iniciando RandomizedSearchCV para RandomForestClassifier...\n",
      "Probando 75 combinaciones de parámetros con 3-fold CV.\n",
      "Fitting 3 folds for each of 75 candidates, totalling 225 fits\n",
      "\n",
      "RandomizedSearchCV completado en 2.82 segundos.\n",
      "\n",
      "--- 5. Resultados del Ajuste de Hiperparámetros (RandomForest) ---\n",
      "Mejor puntuación F1-Weighted (media en CV sobre datos de entrenamiento): 0.8882\n",
      "Mejores hiperparámetros encontrados:\n",
      "{'n_estimators': 200, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': 'log2', 'max_depth': 7, 'bootstrap': True}\n",
      "\n",
      "Importancia de las Características (Random Forest Optimizado):\n",
      "                   feature  importance\n",
      "11         Online boarding    0.186885\n",
      "4                    Class    0.149277\n",
      "3           Type of Travel    0.122864\n",
      "13  Inflight entertainment    0.084234\n",
      "6    Inflight wifi service    0.080817\n",
      "12            Seat comfort    0.055730\n",
      "5          Flight Distance    0.040375\n",
      "14        On-board service    0.037934\n",
      "15        Leg room service    0.032771\n",
      "8   Ease of Online booking    0.031241\n",
      "\n",
      "--- 6. Evaluación Final del Mejor Modelo RandomForest en el CONJUNTO DE PRUEBA ---\n",
      "Métricas en el conjunto de prueba (Random Forest Optimizado):\n",
      "Accuracy: 0.8900\n",
      "F1 Score (Weighted): 0.8897\n",
      "AUC: 0.9458\n",
      "\n",
      "Reporte de Clasificación detallado (Random Forest Optimizado en Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       112\n",
      "           1       0.89      0.85      0.87        88\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.89      0.89      0.89       200\n",
      "weighted avg       0.89      0.89      0.89       200\n",
      "\n",
      "\n",
      "--- 7. Guardando el modelo RandomForest optimizado para la aplicación ---\n",
      "Modelo guardado exitosamente para la app como 'app/ml_models\\random_forest_satisfaction_model.pkl'\n",
      "\n",
      "--- 8. Calculando Overfitting para RandomForest Optimizado ---\n",
      "AUC en Conjunto de Entrenamiento: 0.9821\n",
      "F1 (weighted) en Conjunto de Entrenamiento: 0.9259\n",
      "AUC en Conjunto de Prueba:        0.9458\n",
      "F1 (weighted) en Conjunto de Prueba:        0.8897\n",
      "\n",
      "Diferencia Absoluta F1 (Train - Test): 0.0362\n",
      "Diferencia Absoluta AUC (Train - Test): 0.0363\n",
      "\n",
      "El modelo parece tener un buen balance entre entrenamiento y prueba según el F1-score. ✅\n",
      "El modelo parece tener un buen balance entre entrenamiento y prueba según el AUC. ✅\n",
      "\n",
      "--- PROCESO COMPLETADO CON RANDOMFOREST + RANDOMIZEDSEARCHCV ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score\n",
    "import joblib\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "print(\"\\n--- 4. AJUSTE DE HIPERPARÁMETROS PARA RANDOM FOREST (Enfoque Compañeros) ---\")\n",
    "\n",
    "base_rf_model = RandomForestClassifier(random_state=42)\n",
    "param_distributions_rf_v3 = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 7, 10, 12],\n",
    "    'min_samples_split': [15, 20, 25, 30],\n",
    "    'min_samples_leaf': [8, 10, 12, 15],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "n_folds_rs = 3\n",
    "cv_strategy_rs = StratifiedKFold(n_splits=n_folds_rs, shuffle=True, random_state=42)\n",
    "n_iterations_search = 75\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=base_rf_model,\n",
    "    param_distributions=param_distributions_rf_v3,\n",
    "    n_iter=n_iterations_search,\n",
    "    scoring='f1_weighted',\n",
    "    cv=cv_strategy_rs,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nIniciando RandomizedSearchCV para RandomForestClassifier...\")\n",
    "print(f\"Probando {random_search_rf.n_iter} combinaciones de parámetros con {n_folds_rs}-fold CV.\")\n",
    "start_time = time()\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "end_time = time()\n",
    "print(f\"\\nRandomizedSearchCV completado en {(end_time - start_time):.2f} segundos.\")\n",
    "\n",
    "print(\"\\n--- 5. Resultados del Ajuste de Hiperparámetros (RandomForest) ---\")\n",
    "print(f\"Mejor puntuación F1-Weighted (media en CV sobre datos de entrenamiento): {random_search_rf.best_score_:.4f}\")\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(random_search_rf.best_params_)\n",
    "\n",
    "best_rf_model = random_search_rf.best_estimator_\n",
    "\n",
    "if hasattr(best_rf_model, 'feature_importances_'):\n",
    "    feature_importances_rf = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': best_rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    print(\"\\nImportancia de las Características (Random Forest Optimizado):\")\n",
    "    print(feature_importances_rf.head(10))\n",
    "else:\n",
    "    print(\"\\nEl modelo no tiene el atributo 'feature_importances_'.\")\n",
    "\n",
    "print(\"\\n--- 6. Evaluación Final del Mejor Modelo RandomForest en el CONJUNTO DE PRUEBA ---\")\n",
    "y_pred_test_rf = best_rf_model.predict(X_test)\n",
    "y_proba_test_rf = best_rf_model.predict_proba(X_test)[:, 1]\n",
    "accuracy_test_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "f1_test_rf = f1_score(y_test, y_pred_test_rf, average='weighted')\n",
    "auc_test_rf = roc_auc_score(y_test, y_proba_test_rf)\n",
    "\n",
    "print(\"Métricas en el conjunto de prueba (Random Forest Optimizado):\")\n",
    "print(f\"Accuracy: {accuracy_test_rf:.4f}\")\n",
    "print(f\"F1 Score (Weighted): {f1_test_rf:.4f}\")\n",
    "print(f\"AUC: {auc_test_rf:.4f}\")\n",
    "print(\"\\nReporte de Clasificación detallado (Random Forest Optimizado en Test):\")\n",
    "print(classification_report(y_test, y_pred_test_rf))\n",
    "\n",
    "# --- 7. GUARDAR EL MODELO ENTRENADO PARA LA APP FLASK ---\n",
    "print(\"\\n--- 7. Guardando el modelo RandomForest optimizado para la aplicación ---\")\n",
    "\n",
    "# ASUMIENDO QUE EL NOTEBOOK ESTÁ EN LA RAÍZ DEL PROYECTO, JUNTO A LA CARPETA 'app'\n",
    "ML_MODELS_APP_DIR = 'app/ml_models' # <--- ¡¡¡CAMBIO IMPORTANTE SI EL NOTEBOOK ESTÁ EN LA RAÍZ!!!\n",
    "                                    # Si el notebook está en 'notebooks/', usarías '../app/ml_models'\n",
    "                                    \n",
    "if not os.path.exists(ML_MODELS_APP_DIR):\n",
    "    os.makedirs(ML_MODELS_APP_DIR)\n",
    "    print(f\"Directorio '{ML_MODELS_APP_DIR}' creado para los artefactos del modelo.\")\n",
    "\n",
    "MODEL_APP_FILENAME = 'random_forest_satisfaction_model.pkl' # Nombre del modelo para la app\n",
    "\n",
    "final_model_path_for_app = os.path.join(ML_MODELS_APP_DIR, MODEL_APP_FILENAME)\n",
    "\n",
    "try:\n",
    "    joblib.dump(best_rf_model, final_model_path_for_app)\n",
    "    print(f\"Modelo guardado exitosamente para la app como '{final_model_path_for_app}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el modelo para la app: {e}\")\n",
    "\n",
    "# --- 8. Calcular Overfitting (No cambia) ---\n",
    "# ... (el resto del código de la Celda 4 para el overfitting se mantiene igual) ...\n",
    "print(\"\\n--- 8. Calculando Overfitting para RandomForest Optimizado ---\")\n",
    "y_pred_train_rf = best_rf_model.predict(X_train)\n",
    "y_proba_train_rf = best_rf_model.predict_proba(X_train)[:, 1]\n",
    "train_auc_rf = roc_auc_score(y_train, y_proba_train_rf)\n",
    "train_f1_rf = f1_score(y_train, y_pred_train_rf, average='weighted')\n",
    "\n",
    "print(f\"AUC en Conjunto de Entrenamiento: {train_auc_rf:.4f}\")\n",
    "print(f\"F1 (weighted) en Conjunto de Entrenamiento: {train_f1_rf:.4f}\")\n",
    "print(f\"AUC en Conjunto de Prueba:        {auc_test_rf:.4f}\")\n",
    "print(f\"F1 (weighted) en Conjunto de Prueba:        {f1_test_rf:.4f}\")\n",
    "\n",
    "overfitting_abs_f1 = train_f1_rf - f1_test_rf\n",
    "overfitting_abs_auc = train_auc_rf - auc_test_rf\n",
    "print(f\"\\nDiferencia Absoluta F1 (Train - Test): {overfitting_abs_f1:.4f}\")\n",
    "print(f\"Diferencia Absoluta AUC (Train - Test): {overfitting_abs_auc:.4f}\")\n",
    "\n",
    "if overfitting_abs_f1 > 0.05 :\n",
    "    print(\"\\nAdvertencia: El modelo podría estar sobreajustando según el F1-score (diferencia > 5%). ❌\")\n",
    "else:\n",
    "    print(\"\\nEl modelo parece tener un buen balance entre entrenamiento y prueba según el F1-score. ✅\")\n",
    "if overfitting_abs_auc > 0.05 :\n",
    "    print(\"Advertencia: El modelo podría estar sobreajustando según el AUC (diferencia > 5%). ❌\")\n",
    "else:\n",
    "    print(\"El modelo parece tener un buen balance entre entrenamiento y prueba según el AUC. ✅\")\n",
    "\n",
    "print(\"\\n--- PROCESO COMPLETADO CON RANDOMFOREST + RANDOMIZEDSEARCHCV ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
